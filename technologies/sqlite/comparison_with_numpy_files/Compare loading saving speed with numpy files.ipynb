{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "import numpy\n",
    "import h5py\n",
    "\n",
    "import qcodes\n",
    "from qcodes import (\n",
    "    initialise_or_create_database_at, load_or_create_experiment, \n",
    "    Measurement, Parameter,\n",
    "    load_by_id\n",
    ")\n",
    "from qcodes.dataset.data_export import get_data_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save_load_speed_benchmarking#sqlite3_from_qcodes#1@C:\\Users\\a-miasta\\AppData\\Local\\Temp\\tmpouuqbdsp.db\n",
       "------------------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_db_file = TemporaryFile(suffix='.db')\n",
    "temp_db_file.close()\n",
    "initialise_or_create_database_at(temp_db_file.name)\n",
    "load_or_create_experiment('save_load_speed_benchmarking', 'sqlite3_from_qcodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading speed\n",
    "\n",
    "Let's define an iterator function that simulates a measurement process by just returning dummy data of a predefined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts_in_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_measurement_data(n_pts_in_dim):\n",
    "    \"\"\"\n",
    "    This iterator represents the code that obtains\n",
    "    measurement data. For the sake of example, it\n",
    "    just returns random dummy data: 4 dimensions, \n",
    "    `n_pts_in_dim` per each dimension (which becomes\n",
    "    `n_pts_in_dim**4` data points).\n",
    "    \n",
    "    Args:\n",
    "        n_pts_in_dim\n",
    "    \n",
    "    Returns:\n",
    "        tuple of values of the 4 dimensions obtain\n",
    "        at a single \"measurement\" iteration\n",
    "    \"\"\"\n",
    "    for s1_val in range(n_pts_in_dim):\n",
    "        for s2_val in range(n_pts_in_dim):\n",
    "            magn_vals, phas_vals = np.meshgrid(\n",
    "                np.random.rand(n_pts_in_dim),\n",
    "                np.random.rand(n_pts_in_dim),\n",
    "            )\n",
    "            magn_vals = np.reshape(magn_vals, -1)\n",
    "            phas_vals = np.reshape(phas_vals, -1)\n",
    "            \n",
    "            yield s1_val, s2_val, magn_vals, phas_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via QCoDeS DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Parameter('s1', label='Setting 1', unit='V', get_cmd=None, set_cmd=None)\n",
    "s2 = Parameter('s2', label='Setting 2', unit='V', get_cmd=None, set_cmd=None)\n",
    "magn = Parameter('magn', label='Magnitude', unit='V', get_cmd=None, set_cmd=None)\n",
    "phas = Parameter('phas', label='Phase', unit='deg', get_cmd=None, set_cmd=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with 'numeric' type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = Measurement()\n",
    "\n",
    "meas.register_parameter(s1)\n",
    "meas.register_parameter(s2)\n",
    "meas.register_parameter(magn, setpoints=(s1, s2))\n",
    "meas.register_parameter(phas, setpoints=(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas.write_period = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experimental run with id: 44\n",
      "Data saving to dataset with 'numeric' paramtype took 3.8605869999992137 s\n",
      "Starting experimental run with id: 45\n",
      "Data saving to dataset with 'numeric' paramtype took 4.151191499999186 s\n",
      "Starting experimental run with id: 46\n",
      "Data saving to dataset with 'numeric' paramtype took 4.8023025000002235 s\n",
      "Starting experimental run with id: 47\n",
      "Data saving to dataset with 'numeric' paramtype took 5.033625399999437 s\n",
      "Starting experimental run with id: 48\n",
      "Data saving to dataset with 'numeric' paramtype took 5.1586685000002035 s\n",
      "Starting experimental run with id: 49\n",
      "Data saving to dataset with 'numeric' paramtype took 4.366736900001342 s\n",
      "Starting experimental run with id: 50\n",
      "Data saving to dataset with 'numeric' paramtype took 4.045378900000287 s\n",
      "Starting experimental run with id: 51\n",
      "Data saving to dataset with 'numeric' paramtype took 3.8398373999989417 s\n",
      "4.65 s ± 483 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with meas.run() as datasaver:\n",
    "    \n",
    "    t0_dataset_numeric = time.perf_counter()\n",
    "    \n",
    "    for s1_val, s2_val, magn_vals, phas_vals in produce_measurement_data(n_pts_in_dim):\n",
    "        \n",
    "        datasaver.add_result((s1, s1_val), (s2, s2_val), (magn, magn_vals),\n",
    "                             (phas, phas_vals))\n",
    "    \n",
    "t1_dataset_numeric = time.perf_counter()\n",
    "print(f\"Data saving to dataset with 'numeric' paramtype took {t1_dataset_numeric-t0_dataset_numeric} s\")\n",
    "\n",
    "dataset = datasaver.dataset\n",
    "run_id = dataset.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_by_id(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.53 s ± 71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# returns list of rows, as in sqlite (each row is a list where every item corresponds to the column)\n",
    "# data = dataset.get_data(*datasaver.dataset.parameters.split(','))\n",
    "data = dataset.get_data(*dataset.parameters.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way is to use get_values and obtain values of each parameter one by one;\n",
    "# but get_data_by_id uses it already, so let's not repeat it\n",
    "# data = dataset.get_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 ms ± 6.19 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# returns list of lists of dicts with data and metadata;\n",
    "# the first list contains elements for each dependent parameter;\n",
    "# second list contains all the independent parameters, \n",
    "# and the last element is the dependent parameter\n",
    "data = get_data_by_id(datasaver.dataset.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.85 s ± 1.25 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data = get_data_by_id(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with 'array' type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = Measurement()\n",
    "\n",
    "meas.register_parameter(s1)\n",
    "meas.register_parameter(s2)\n",
    "meas.register_parameter(magn, setpoints=(s1, s2), paramtype='array')\n",
    "meas.register_parameter(phas, setpoints=(s1, s2), paramtype='array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas.write_period = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experimental run with id: 60\n",
      "Data saving to dataset with 'array' paramtype took 0.3064309000001231 s\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "with meas.run() as datasaver:\n",
    "    \n",
    "    t0_dataset_array = time.perf_counter()\n",
    "    \n",
    "    for s1_val, s2_val, magn_vals, phas_vals in produce_measurement_data(n_pts_in_dim):\n",
    "        \n",
    "        datasaver.add_result((s1, s1_val), (s2, s2_val), (magn, magn_vals),\n",
    "                             (phas, phas_vals))\n",
    "    \n",
    "t1_dataset_array = time.perf_counter()\n",
    "print(f\"Data saving to dataset with 'array' paramtype took {t1_dataset_array-t0_dataset_array} s\")\n",
    "\n",
    "dataset = datasaver.dataset\n",
    "run_id = dataset.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_by_id(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 ms ± 5.77 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# returns list of rows, as in sqlite (each row is a list where every item corresponds to the column)\n",
    "data = dataset.get_data(*dataset.parameters.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way is to use get_values and obtain values of each parameter one by one;\n",
    "# but get_data_by_id uses it already, so let's not repeat it\n",
    "# data = dataset.get_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 ms ± 6.45 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# returns list of lists of dicts with data and metadata;\n",
    "# the first list contains elements for each dependent parameter;\n",
    "# second list contains all the independent parameters, \n",
    "# and the last element is the dependent parameter\n",
    "# data = get_data_by_id(datasaver.dataset.run_id)\n",
    "data = get_data_by_id(dataset.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via numpy npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saving to numpy npy file took 0.05319410000083735 s\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "outfile = TemporaryFile()\n",
    "outfile.close()\n",
    "\n",
    "t0_npy = time.perf_counter()\n",
    "\n",
    "results_np = np.zeros((4, n_pts_in_dim**4))\n",
    "last_index = 0\n",
    "\n",
    "for s1_val, s2_val, magn_vals, phas_vals in produce_measurement_data(n_pts_in_dim):\n",
    "    \n",
    "    n_pts = len(magn_vals)\n",
    "\n",
    "    results_np[0, last_index:last_index+n_pts] = s1_val\n",
    "    results_np[1, last_index:last_index+n_pts] = s2_val\n",
    "    results_np[2, last_index:last_index+n_pts] = magn_vals\n",
    "    results_np[3, last_index:last_index+n_pts] = phas_vals\n",
    "\n",
    "    last_index += n_pts\n",
    "            \n",
    "np.save(outfile.name, results_np)\n",
    "\n",
    "t1_npy = time.perf_counter()\n",
    "print(f\"Data saving to numpy npy file took {t1_npy-t0_npy} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.88 ms ± 901 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data = np.load(outfile.name+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via numpy npy file and memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saving to numpy npy file via memory map took 0.06714089999877615 s\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "outfile = TemporaryFile()\n",
    "outfile.close()\n",
    "\n",
    "t0_npy_mm = time.perf_counter()\n",
    "\n",
    "results_mm = np.lib.format.open_memmap(\n",
    "    outfile.name, mode='w+', shape=(4, n_pts_in_dim**4))\n",
    "\n",
    "last_index = 0\n",
    "\n",
    "for s1_val, s2_val, magn_vals, phas_vals in produce_measurement_data(n_pts_in_dim):\n",
    "    \n",
    "    n_pts = len(magn_vals)\n",
    "\n",
    "    results_mm[0, last_index:last_index+n_pts] = s1_val\n",
    "    results_mm[1, last_index:last_index+n_pts] = s2_val\n",
    "    results_mm[2, last_index:last_index+n_pts] = magn_vals\n",
    "    results_mm[3, last_index:last_index+n_pts] = phas_vals\n",
    "\n",
    "    last_index += n_pts\n",
    "            \n",
    "del results_mm  # closes the file and performs final flushing\n",
    "\n",
    "t1_npy_mm = time.perf_counter()\n",
    "print(f\"Data saving to numpy npy file via memory map took {t1_npy_mm-t0_npy_mm} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.85 ms ± 513 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data = np.load(outfile.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via hdf5 file (directly to the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saving to hdf5 file took 0.4443922000009479 s\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "outfile = TemporaryFile()\n",
    "outfile.close()\n",
    "\n",
    "t0_hdf5_2 = time.perf_counter()\n",
    "\n",
    "last_index = 0\n",
    "\n",
    "with h5py.File(outfile.name, 'w') as f:\n",
    "    ds = f.create_dataset('results', shape=(4, n_pts_in_dim**4))\n",
    "\n",
    "    for s1_val, s2_val, magn_vals, phas_vals in produce_measurement_data(n_pts_in_dim):\n",
    "\n",
    "        n_pts = len(magn_vals)\n",
    "\n",
    "        ds[0, last_index:last_index+n_pts] = s1_val\n",
    "        ds[1, last_index:last_index+n_pts] = s2_val\n",
    "        ds[2, last_index:last_index+n_pts] = magn_vals\n",
    "        ds[3, last_index:last_index+n_pts] = phas_vals\n",
    "\n",
    "        last_index += n_pts    \n",
    "\n",
    "t1_hdf5_2 = time.perf_counter()\n",
    "print(f\"Data saving to hdf5 file took {t1_hdf5_2-t0_hdf5_2} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.04 ms ± 84.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with h5py.File(outfile.name, 'r') as f:\n",
    "    data = np.array(f['results'], copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via hdf5 file (from allocated numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saving to hdf5 file took 0.04720199999997021 s\n",
      "Data saving to hdf5 file took 0.061583200000086435 s\n",
      "Data saving to hdf5 file took 0.04233099999987644 s\n",
      "Data saving to hdf5 file took 0.04147600000010243 s\n",
      "Data saving to hdf5 file took 0.04036139999993793 s\n",
      "Data saving to hdf5 file took 0.06866820000004736 s\n",
      "Data saving to hdf5 file took 0.041715699999940625 s\n",
      "Data saving to hdf5 file took 0.04046949999997196 s\n",
      "Data saving to hdf5 file took 0.040578400000185866 s\n",
      "Data saving to hdf5 file took 0.039881400000012945 s\n",
      "Data saving to hdf5 file took 0.04231320000008054 s\n",
      "Data saving to hdf5 file took 0.059740500000089014 s\n",
      "Data saving to hdf5 file took 0.042064800000161995 s\n",
      "Data saving to hdf5 file took 0.04004609999992681 s\n",
      "Data saving to hdf5 file took 0.04069900000013149 s\n",
      "Data saving to hdf5 file took 0.04015419999996084 s\n",
      "Data saving to hdf5 file took 0.05341750000002321 s\n",
      "Data saving to hdf5 file took 0.05221260000007533 s\n",
      "Data saving to hdf5 file took 0.051638200000070356 s\n",
      "Data saving to hdf5 file took 0.04024329999992915 s\n",
      "Data saving to hdf5 file took 0.03953209999986029 s\n",
      "Data saving to hdf5 file took 0.06216199999994387 s\n",
      "Data saving to hdf5 file took 0.04424519999997756 s\n",
      "Data saving to hdf5 file took 0.04371149999997215 s\n",
      "Data saving to hdf5 file took 0.04921340000009877 s\n",
      "Data saving to hdf5 file took 0.04335480000008829 s\n",
      "Data saving to hdf5 file took 0.07900309999990895 s\n",
      "Data saving to hdf5 file took 0.09785130000000208 s\n",
      "Data saving to hdf5 file took 0.08676260000015645 s\n",
      "Data saving to hdf5 file took 0.07366699999988668 s\n",
      "Data saving to hdf5 file took 0.04504870000005212 s\n",
      "Data saving to hdf5 file took 0.0426578999999947 s\n",
      "Data saving to hdf5 file took 0.042141500000070664 s\n",
      "Data saving to hdf5 file took 0.043351600000050894 s\n",
      "Data saving to hdf5 file took 0.046963300000015806 s\n",
      "Data saving to hdf5 file took 0.0507082999999966 s\n",
      "Data saving to hdf5 file took 0.04203000000006796 s\n",
      "Data saving to hdf5 file took 0.04285899999990761 s\n",
      "Data saving to hdf5 file took 0.04241720000004534 s\n",
      "Data saving to hdf5 file took 0.046512099999972634 s\n",
      "Data saving to hdf5 file took 0.08949150000012196 s\n",
      "Data saving to hdf5 file took 0.15014800000017203 s\n",
      "Data saving to hdf5 file took 0.11075060000007397 s\n",
      "Data saving to hdf5 file took 0.0632832999999664 s\n",
      "Data saving to hdf5 file took 0.07844410000006974 s\n",
      "Data saving to hdf5 file took 0.04349630000001525 s\n",
      "Data saving to hdf5 file took 0.040376100000003134 s\n",
      "Data saving to hdf5 file took 0.040328300000055606 s\n",
      "Data saving to hdf5 file took 0.039664700000002995 s\n",
      "Data saving to hdf5 file took 0.0455511000000115 s\n",
      "Data saving to hdf5 file took 0.05427690000010443 s\n",
      "Data saving to hdf5 file took 0.04215210000006664 s\n",
      "Data saving to hdf5 file took 0.044581200000038734 s\n",
      "Data saving to hdf5 file took 0.04202680000003056 s\n",
      "Data saving to hdf5 file took 0.05255929999998443 s\n",
      "Data saving to hdf5 file took 0.04292400000008456 s\n",
      "Data saving to hdf5 file took 0.04044590000012249 s\n",
      "Data saving to hdf5 file took 0.04711540000016612 s\n",
      "Data saving to hdf5 file took 0.04241759999990791 s\n",
      "Data saving to hdf5 file took 0.07197519999999713 s\n",
      "Data saving to hdf5 file took 0.0444231999999829 s\n",
      "Data saving to hdf5 file took 0.04395199999999022 s\n",
      "Data saving to hdf5 file took 0.0837525999997979 s\n",
      "Data saving to hdf5 file took 0.08681749999982458 s\n",
      "Data saving to hdf5 file took 0.1206824000000779 s\n",
      "Data saving to hdf5 file took 0.06031310000003032 s\n",
      "Data saving to hdf5 file took 0.05858149999994566 s\n",
      "Data saving to hdf5 file took 0.07436059999986355 s\n",
      "Data saving to hdf5 file took 0.05383569999980864 s\n",
      "Data saving to hdf5 file took 0.08537679999994907 s\n",
      "Data saving to hdf5 file took 0.149933400000009 s\n",
      "Data saving to hdf5 file took 0.10106709999990926 s\n",
      "Data saving to hdf5 file took 0.04586820000008629 s\n",
      "Data saving to hdf5 file took 0.04135709999991377 s\n",
      "Data saving to hdf5 file took 0.04271779999999126 s\n",
      "Data saving to hdf5 file took 0.04508499999997184 s\n",
      "Data saving to hdf5 file took 0.05372579999993832 s\n",
      "Data saving to hdf5 file took 0.04584769999996752 s\n",
      "Data saving to hdf5 file took 0.04208100000005288 s\n",
      "Data saving to hdf5 file took 0.0412008999999216 s\n",
      "Data saving to hdf5 file took 0.042378400000188776 s\n",
      "60.6 ms ± 13.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "outfile = TemporaryFile()\n",
    "outfile.close()\n",
    "\n",
    "t0_hdf5 = time.perf_counter()\n",
    "\n",
    "results_np = np.zeros((4, n_pts_in_dim**4))\n",
    "last_index = 0\n",
    "\n",
    "for s1_val, s2_val, magn_vals, phas_vals in produce_measurement_data(n_pts_in_dim):\n",
    "            \n",
    "    n_pts = len(magn_vals)\n",
    "\n",
    "    results_np[0, last_index:last_index+n_pts] = s1_val\n",
    "    results_np[1, last_index:last_index+n_pts] = s2_val\n",
    "    results_np[2, last_index:last_index+n_pts] = magn_vals\n",
    "    results_np[3, last_index:last_index+n_pts] = phas_vals\n",
    "\n",
    "    last_index += n_pts\n",
    "            \n",
    "with h5py.File(outfile.name, 'w') as f:\n",
    "    ds = f.create_dataset('results', data=results_np)\n",
    "\n",
    "t1_hdf5 = time.perf_counter()\n",
    "print(f\"Data saving to hdf5 file took {t1_hdf5-t0_hdf5} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qcodes]",
   "language": "python",
   "name": "conda-env-qcodes-py"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
